{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee2532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from torch import Tensor\n",
    "from joblib import dump, load\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1174e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"CapstoneProject_ProjectCode_NikhilKorlipara.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1l2PyW0zAGwOe4JMYFruFvACWYCTJ_7ZE\n",
    "\"\"\"\n",
    "class lazyload(Dataset):\n",
    "    def __init__(self, path, isTrain=True, transform = None):\n",
    "        self.transform = transform\n",
    "        path = path + ('train/' if isTrain else 'test/')\n",
    "        self.pathx = path + 'X/'\n",
    "        self.pathy = path + 'Y/'\n",
    "        self.data = os.listdir(self.pathx)\n",
    "        self.isTrain = isTrain\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.data[idx]\n",
    "        img0 = cv2.imread(self.pathx + f + '/rgb/0.png')\n",
    "        img1 = cv2.imread(self.pathx + f + '/rgb/1.png')\n",
    "        img2 = cv2.imread(self.pathx + f + '/rgb/2.png')\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        depth = np.load(self.pathx + f + '/depth.npy')\n",
    "        field_id = pkl.load(open(self.pathx + f + '/field_id.pkl', 'rb'))\n",
    "        if self.isTrain == False:\n",
    "            return (img0, img1, img2, depth, torch.tensor(int(field_id)))\n",
    "        y = np.load(self.pathy + f + '.npy')\n",
    "        return (img0, img1, img2, depth, torch.tensor(int(field_id))), torch.tensor(y)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class norm_data:\n",
    "    def conv_tensor_to_array(self, data, isTrain=True):\n",
    "        len_data = len(data)\n",
    "        if isTrain:\n",
    "            (img0_, img1_, img2_, depth_, field_id_), y_ = data[0]\n",
    "            img_shape, img1_shape, img2_shape, depth_shape, len_y = img0_.shape, img1_.shape, img2_.shape, depth_.shape, len(y_)\n",
    "            y_ar = np.empty(shape=(len_data, len_y))\n",
    "        else:\n",
    "            (img0_, img1_, img2_, depth_, field_id_) = data[0]\n",
    "            img_shape, img1_shape, img2_shape, depth_shape = img0_.shape, img1_.shape, img2_.shape, depth_.shape\n",
    "            field_id_ar = np.empty(shape=(len_data, 1))\n",
    "        img0_ar = np.empty(shape=(len_data, img_shape[0], img_shape[1], img_shape[2]))\n",
    "        img1_ar = np.empty(shape=(len_data, img1_shape[0], img1_shape[1], img1_shape[2]))\n",
    "        img2_ar = np.empty(shape=(len_data, img2_shape[0], img2_shape[1], img2_shape[2]))\n",
    "        depth_ar = np.empty(shape=(len_data, depth_shape[0], depth_shape[1], depth_shape[2]))\n",
    "\n",
    "        for inx, d in enumerate(data):\n",
    "            # print(inx)\n",
    "            if isTrain:\n",
    "                (img0, img1, img2, depth, field_id), y = d\n",
    "                y_ar[inx, :] = np.array(y)\n",
    "                img0_ar[inx, :, :, :] = img0\n",
    "                img1_ar[inx, :, :, :] = img1\n",
    "                img2_ar[inx, :, :, :] = img2\n",
    "                depth_ar[inx, :, :, :] = depth\n",
    "            else:\n",
    "                (img0, img1, img2, depth, field_id) = d\n",
    "                field_id_ar[inx] = field_id.numpy()\n",
    "                img0_ar[inx, :, :, :] = img0\n",
    "                img1_ar[inx, :, :, :] = img1\n",
    "                img2_ar[inx, :, :, :] = img2\n",
    "                depth_ar[inx, :, :, :] = depth\n",
    "        if isTrain:\n",
    "            return img0_ar, img1_ar, img2_ar, depth_ar, y_ar\n",
    "        return img0_ar, img1_ar, img2_ar, depth_ar, field_id_ar\n",
    "\n",
    "    def norm_depth(self, depth):\n",
    "        min_num = np.min(depth)\n",
    "        max_num = np.max(depth)\n",
    "        normalized_depth = (depth - min_num) / (max_num - min_num)\n",
    "        return normalized_depth\n",
    "\n",
    "    def norm_image(self, img):\n",
    "        return (img/255.0)\n",
    "      \n",
    "    def add_depth_to_img(self, depth, img, which_img=0):\n",
    "        new_img = np.empty(shape=(img.shape[0], img.shape[1], img.shape[2], img.shape[3]+1))\n",
    "        depth0 = depth[:, which_img, :, :]\n",
    "        for inx, _ in enumerate(img):\n",
    "            depth_4d = np.expand_dims(depth0[inx], 2)\n",
    "            new_img[inx] = np.concatenate((img[inx], depth_4d), axis=2)\n",
    "        return new_img\n",
    "\n",
    "    def data_reshaping(self, data):\n",
    "        s = data.shape[0]\n",
    "        c = data.shape[3]\n",
    "        h = data.shape[1]\n",
    "        w = data.shape[2]\n",
    "        newdata = np.empty(shape=(s, c, h, w))\n",
    "\n",
    "        for i in range(c):\n",
    "            newdata[:, i, :, :] = data[:, :, :, i]\n",
    "        return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed23a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb73d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e50019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = norm_data()\n",
    "data_train = lazyload('./Downloads/Capstone_Project/lazydata/', isTrain = True)\n",
    "data_test = lazyload('./Downloads/Capstone_Project/lazydata/', isTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1504fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "img0_array_test, img1_array_test, img2_array_test, depth_array_test, field_id_array = dp.conv_tensor_to_array(data=data_test, isTrain=False)\n",
    "img0_array_train, img1_array_train, img2_array_train, depth_array_train, y_array = dp.conv_tensor_to_array(data=data_train, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7793935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed test reshaping\n",
      "completed normalized depth train\n",
      "completed reshaping img0_array_train\n",
      "completed reshaping new_img1_train\n",
      "completed reshaping img2_array_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print(type(depth_array_test), np.shape(depth_array_test))\n",
    "depth_array_test = dp.norm_depth(depth_array_test)\n",
    "\n",
    "img0_array_test = dp.norm_image(img0_array_test)\n",
    "img0_array_test = dp.add_depth_to_img(depth_array_test, img0_array_test)\n",
    "img0_array_test = dp.data_reshaping(img0_array_test)\n",
    "gc.collect()\n",
    "\n",
    "img1_array_test = dp.norm_image(img1_array_test)\n",
    "img1_array_test = dp.add_depth_to_img(depth_array_test, img1_array_test)\n",
    "img1_array_test = dp.data_reshaping(img1_array_test)\n",
    "gc.collect()\n",
    "\n",
    "img2_array_test = dp.norm_image(img2_array_test)\n",
    "img2_array_test = dp.add_depth_to_img(depth_array_test, img2_array_test)\n",
    "img2_array_test = dp.data_reshaping(img2_array_test)\n",
    "gc.collect()\n",
    "\n",
    "print('completed test reshaping')\n",
    "\n",
    "depth_array_train = dp.norm_depth(depth_array_train)\n",
    "print('completed normalized depth train')\n",
    "gc.collect()\n",
    "\n",
    "img0_array_train = dp.norm_image(img0_array_train)\n",
    "img0_array_train = dp.add_depth_to_img(img=img0_array_train, depth=depth_array_train, which_img = 0)\n",
    "img0_array_train = dp.data_reshaping(img0_array_train)\n",
    "print('completed reshaping img0_array_train')\n",
    "gc.collect()\n",
    "\n",
    "img1_array_train = dp.norm_image(img1_array_train)\n",
    "img1_array_train = dp.add_depth_to_img(img=img1_array_train, depth=depth_array_train, which_img = 1)\n",
    "img1_array_train = dp.data_reshaping(img1_array_train)\n",
    "print('completed reshaping img1_array_train')\n",
    "gc.collect()\n",
    "\n",
    "img2_array_train = dp.norm_image(img2_array_train)\n",
    "img2_array_train = dp.add_depth_to_img(img=img2_array_train, depth=depth_array_train, which_img = 2)\n",
    "img2_array_train = dp.data_reshaping(img2_array_train)\n",
    "print('completed reshaping img2_array_train')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e8bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_img0 = [img0_array_test, field_id_array]\n",
    "testX_img1 = [img1_array_test, field_id_array]\n",
    "testX_img2 = [img2_array_test, field_id_array]\n",
    "train_img0 = [img0_array_train, y_array]\n",
    "train_img1 = [img1_array_train, y_array]\n",
    "train_img2 = [img2_array_train, y_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780c4ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessed_train_data2.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(testX_img0, 'preprocessed_test_img0.joblib')\n",
    "dump(testX_img1, 'preprocessed_test_img1.joblib')\n",
    "dump(testX_img2, 'preprocessed_test_img2.joblib')\n",
    "dump(train_img0, 'preprocessed_train_data0.joblib')\n",
    "dump(train_img1, 'preprocessed_train_data1.joblib')\n",
    "dump(train_img2, 'preprocessed_train_data2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090564f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
